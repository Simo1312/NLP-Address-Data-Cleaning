{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19cb2355",
   "metadata": {},
   "source": [
    "NLP - Natural Language Processing is a branch of AI that focuses on the interaction between computers and human languages. The idea of NLP is to enable computers to understand, execute, and regenerate human language while keeping it meaningful and useful. As of now, the main areas we can see NLP are: chatbots and virtual assistants, translation services and sustomer support.\n",
    "\n",
    "Address Data Cleaning is the process of improving the quality of address data by correcting errors, standardizing formats, and removing inconsistencies or duplicates. This process is critical for ensuring that address data is accurate, reliable, and usable for various purposes, such as customer communication and delivery. The most common steps in address data cleaning include data validation, standardization, error correction, deduplication, geocoding, and normalization.\n",
    "\n",
    "In this project, we will focus on standardization, error correction, and deduplication while using a normalized dataset containing a number of U.S. addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe5a2fc5fe6d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:07.962751Z",
     "start_time": "2024-12-17T15:13:07.958746Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import pkg_resources\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1725e7e",
   "metadata": {},
   "source": [
    "pandas - python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
    "\n",
    "symspell - an algorithm for finding all strings in very short time within a fixed edit distance from a large list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7938f643de67b06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:09.230529Z",
     "start_time": "2024-12-17T15:13:09.220912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      street            city state    zip\n",
      "0        777 Brockton Avenue        Abington    MA   2351\n",
      "1           30 Memrial Drive            Avon    MA   2322\n",
      "2        250 Hartford Avenue      Bellingham    MA   2019\n",
      "3        777 brockton Avenue        Abington    MA   2351\n",
      "4              700 Oak Stret        Brockton    MA   2301\n",
      "..                       ...             ...   ...    ...\n",
      "230      1501 Skyland Blvd E      Tuscaloosa    AL  35405\n",
      "231             3501 20th Av          Valley    AL  36854\n",
      "232  1300 Montgomery Highway  Vestavia Hills    AL  35216\n",
      "233          4538 Us Hwy 231        Wetumpka    AL  36092\n",
      "234           2575 Us Hwy 43        Winfield    AL  35594\n",
      "\n",
      "[235 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "addresses_df = pd.read_csv('list_of_real_usa_addresses.csv')\n",
    "print(addresses_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a382395c83703d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:18.024634Z",
     "start_time": "2024-12-17T15:13:18.014050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Preprocessing the text\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    ")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16629159",
   "metadata": {},
   "source": [
    " Initializing a SymSpell instance for efficient spell correction with a maximum edit distance of 2. It loads a frequency dictionary (our frequency_dictionary_en file) that maps words to their occurrence frequencies, enabling accurate suggestions for misspelled words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e6143aea93fdb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:20.537134Z",
     "start_time": "2024-12-17T15:13:20.531091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Commonly used address terms mapping to standard terms\n",
    "ADDRESS_TERMS = {\n",
    "    'street': ['st', 'street', 'str'],\n",
    "    'avenue': ['ave', 'avenue', 'av'],\n",
    "    'drive': ['dr', 'drive', 'drv'],\n",
    "    'road': ['rd', 'road'],\n",
    "    'lane': ['ln', 'lane'],\n",
    "    'circle': ['cir', 'circle', 'crcl'],\n",
    "    'boulevard': ['blvd', 'boulevard', 'boul'],\n",
    "    'place': ['pl', 'place'],\n",
    "    'court': ['ct', 'court', 'crt'],\n",
    "    'square': ['sq', 'square'],\n",
    "    'highway': ['hwy', 'highway', 'hiway'],\n",
    "    'parkway': ['pkwy', 'parkway'],\n",
    "    'expressway': ['expy', 'expressway'],\n",
    "    'plaza': ['plz', 'plaza'],\n",
    "    'trail': ['tr', 'trail', 'trl'],\n",
    "    'way': ['wy', 'way'],\n",
    "    'alley': ['aly', 'alley'],\n",
    "    'terrace': ['ter', 'terrace'],\n",
    "    'pike': ['pk', 'pike'],\n",
    "    'grove': ['grv', 'grove'],\n",
    "    'ridge': ['rdg', 'ridge'],\n",
    "    'north': ['n', 'no', 'nth'],\n",
    "    'south': ['s', 'so', 'sth'],\n",
    "    'east': ['e', 'ea'],\n",
    "    'west': ['w', 'we'],\n",
    "    'northeast': ['ne'],\n",
    "    'northwest': ['nw'],\n",
    "    'southeast': ['se'],\n",
    "    'southwest': ['sw']\n",
    "}\n",
    "\n",
    "# All US States mapping to their abbreviations\n",
    "US_STATES = {\n",
    "    'AL': ['alabama', 'al'],\n",
    "    'AK': ['alaska', 'ak'],\n",
    "    'AZ': ['arizona', 'az'],\n",
    "    'AR': ['arkansas', 'ar'],\n",
    "    'CA': ['california', 'ca', 'calif'],\n",
    "    'CO': ['colorado', 'co'],\n",
    "    'CT': ['connecticut', 'ct', 'conn'],\n",
    "    'DE': ['delaware', 'de'],\n",
    "    'FL': ['florida', 'fl', 'fla'],\n",
    "    'GA': ['georgia', 'ga'],\n",
    "    'HI': ['hawaii', 'hi'],\n",
    "    'ID': ['idaho', 'id'],\n",
    "    'IL': ['illinois', 'il'],\n",
    "    'IN': ['indiana', 'in'],\n",
    "    'IA': ['iowa', 'ia'],\n",
    "    'KS': ['kansas', 'ks'],\n",
    "    'KY': ['kentucky', 'ky'],\n",
    "    'LA': ['louisiana', 'la'],\n",
    "    'ME': ['maine', 'me'],\n",
    "    'MD': ['maryland', 'md'],\n",
    "    'MA': ['massachusetts', 'ma', 'mass'],\n",
    "    'MI': ['michigan', 'mi', 'mich'],\n",
    "    'MN': ['minnesota', 'mn', 'minn'],\n",
    "    'MS': ['mississippi', 'ms'],\n",
    "    'MO': ['missouri', 'mo'],\n",
    "    'MT': ['montana', 'mt'],\n",
    "    'NE': ['nebraska', 'ne', 'nebr'],\n",
    "    'NV': ['nevada', 'nv'],\n",
    "    'NH': ['new hampshire', 'nh'],\n",
    "    'NJ': ['new jersey', 'nj'],\n",
    "    'NM': ['new mexico', 'nm'],\n",
    "    'NY': ['new york', 'ny'],\n",
    "    'NC': ['north carolina', 'nc'],\n",
    "    'ND': ['north dakota', 'nd'],\n",
    "    'OH': ['ohio', 'oh'],\n",
    "    'OK': ['oklahoma', 'ok'],\n",
    "    'OR': ['oregon', 'or'],\n",
    "    'PA': ['pennsylvania', 'pa'],\n",
    "    'RI': ['rhode island', 'ri'],\n",
    "    'SC': ['south carolina', 'sc'],\n",
    "    'SD': ['south dakota', 'sd'],\n",
    "    'TN': ['tennessee', 'tn', 'tenn'],\n",
    "    'TX': ['texas', 'tx'],\n",
    "    'UT': ['utah', 'ut'],\n",
    "    'VT': ['vermont', 'vt'],\n",
    "    'VA': ['virginia', 'va'],\n",
    "    'WA': ['washington', 'wa', 'wash'],\n",
    "    'WV': ['west virginia', 'wv'],\n",
    "    'WI': ['wisconsin', 'wi', 'wis', 'wisc'],\n",
    "    'WY': ['wyoming', 'wy'],\n",
    "    'DC': ['district of columbia', 'dc'],\n",
    "    'PR': ['puerto rico', 'pr'],\n",
    "    'VI': ['virgin islands', 'vi'],\n",
    "    'GU': ['guam', 'gu'],\n",
    "    'MP': ['northern mariana islands', 'mp'],\n",
    "    'AS': ['american samoa', 'as']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf21b1",
   "metadata": {},
   "source": [
    "Dictionaries that map common street suffixes, directional terms and states to their variations or abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c3d6b5db9be810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:24.966957Z",
     "start_time": "2024-12-17T15:13:21.574193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to standardize zip codes to 5 digit standard\n",
    "def standardize_zip(zip_code):\n",
    "\n",
    "    if pd.isna(zip_code) or zip_code == '':\n",
    "        return None\n",
    "    zip_str = re.sub(r'\\D', '', str(zip_code))\n",
    "    if len(zip_str) > 5:\n",
    "        zip_str = zip_str[:5]\n",
    "    return zip_str.zfill(5)\n",
    "\n",
    "\n",
    "# Function to standardize state abbreviations\n",
    "def standardize_state(state):\n",
    "    if pd.isna(state) or state == '':\n",
    "        return None\n",
    "    \n",
    "    state = state.lower().strip()\n",
    "    if state.upper() in US_STATES.keys():\n",
    "        return state.upper()\n",
    "\n",
    "    for code, variations in US_STATES.items():\n",
    "        if state in variations:\n",
    "            return code\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ba36e",
   "metadata": {},
   "source": [
    "The U.S. uses 5 digit ZIP codes so the first function takes a ZIP code as input, removes non-digit characters, and ensures it is exactly 5 digits long by shortening or left-padding with zeros as needed. If the entry is null or empty the function returns none.\n",
    "\n",
    "The standardize_state function takes a state name or abbreviation as input, searches the dictionary (both key and value) for a match and returns its uppercase two-letter postal code.\n",
    "\n",
    "Both of these functions ensure consistent formating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5d73187669d0e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:42.802696Z",
     "start_time": "2024-12-17T15:13:42.790480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clean and standardize street address\n",
    "def clean_street_address(address):\n",
    "    if pd.isna(address) or address == '':\n",
    "        return None\n",
    "        \n",
    "    address = address.lower().strip()\n",
    "    address = re.sub(r'[^\\w\\s#-]', '', address)\n",
    "    words = address.split()\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isdigit() or '#' in word:\n",
    "            cleaned_words.append(word)\n",
    "            continue\n",
    "\n",
    "        term_found = False\n",
    "        for standard, variations in ADDRESS_TERMS.items():\n",
    "            if word in variations:\n",
    "                cleaned_words.append(standard)\n",
    "                term_found = True\n",
    "                break\n",
    "        \n",
    "        if not term_found:\n",
    "            suggestions = sym_spell.lookup(\n",
    "                word,\n",
    "                Verbosity.CLOSEST,\n",
    "                max_edit_distance=2\n",
    "            )\n",
    "            if suggestions:\n",
    "                cleaned_words.append(suggestions[0].term)\n",
    "            else:\n",
    "                cleaned_words.append(word)\n",
    "\n",
    "    cleaned_address = ' '.join(cleaned_words)\n",
    "    return cleaned_address.title()\n",
    "\n",
    "\n",
    "# Function to clean and standardize city name\n",
    "def clean_city(city):\n",
    "    if pd.isna(city) or city == '':\n",
    "        return None\n",
    "\n",
    "    city = city.lower().strip()\n",
    "    city = re.sub(r'[^\\w\\s]', '', city)\n",
    "    suggestions = sym_spell.lookup(\n",
    "        city,\n",
    "        Verbosity.CLOSEST,\n",
    "        max_edit_distance=2\n",
    "    )\n",
    "    \n",
    "    if suggestions:\n",
    "        city = suggestions[0].term\n",
    "        \n",
    "    return city.title()\n",
    "\n",
    "# Apply all cleaning functions to a copy of the dataset\n",
    "def clean_addresses(df):\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df['street'] = cleaned_df['street'].apply(clean_street_address)\n",
    "    cleaned_df['city'] = cleaned_df['city'].apply(clean_city)\n",
    "    cleaned_df['state'] = cleaned_df['state'].apply(standardize_state)\n",
    "    cleaned_df['zip'] = cleaned_df['zip'].apply(standardize_zip)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86ac16",
   "metadata": {},
   "source": [
    "The first function receives a string address, checks and handles empty or null values, removes special characters and corrects the word variation based on our predifined dictionary (ADDRESS_TERMS). If unable to recognize the word, it attempts to correct the word using our spell checking library (symspell) and finally returns the properly formatted string.\n",
    "\n",
    "The second function is similar but handles city string inputs. It checks for and handles empty or null values, converts the input to lowercase, removes non-alphanumeric characters, and uses our spell-checking library to correct typos within a specified edit distance.\n",
    "\n",
    "The last function takes our dataset as input, applies all the previously described functions, and returns a reformatted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d41175212619351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:13:46.408365Z",
     "start_time": "2024-12-17T15:13:46.399977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to remove duplicate addresses\n",
    "def remove_duplicates(df):\n",
    "    duplicates = df[df.duplicated(subset=['street', 'city', 'state', 'zip'], keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        print(\"\\nDuplicate addresses found:\")\n",
    "        print(duplicates[['street', 'city', 'state', 'zip']])\n",
    "        print(f\"\\nTotal duplicates found: {len(duplicates)}\")\n",
    "    before_dedup = len(df)\n",
    "    df = df.drop_duplicates(subset=['street', 'city', 'state', 'zip'], keep='first')\n",
    "    after_dedup = len(df)\n",
    "    print(f\"\\nRemoved {before_dedup - after_dedup} duplicate addresses.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f30d98",
   "metadata": {},
   "source": [
    "This function identifies and removes duplicate rows in our dataset to prevent redundancy. If duplicates are found, it prints all duplicate rows along with their total count. Afterward, it removes the duplicates, keeping only the first occurrences. Finally, it prints the number of rows removed and returns the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901cf3edc3baadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:05:55.852324Z",
     "start_time": "2024-12-17T15:01:59.112273Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_file(input_file, output_file):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    cleaned_df = clean_addresses(df)\n",
    "\n",
    "    # Duplicate removal applied after cleaning and standardization to avoid missing duplicates\n",
    "    cleaned_df = remove_duplicates(cleaned_df)\n",
    "\n",
    "    cleaned_df.to_csv(output_file, index=False)\n",
    "    return cleaned_df\n",
    "\n",
    "cleaned_data = process_file('list_of_real_usa_addresses.csv', 'cleaned_addresses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60962c1",
   "metadata": {},
   "source": [
    "This function reads a CSV file (list_of_real_usa_addresses.csv in our case) and processes it using the previously explained functions. If successful, it saves the cleaned data to a new CSV file and returns the cleaned dataset. It also handles errors, such as a missing file or other unexpected issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
